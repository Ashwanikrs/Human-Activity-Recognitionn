{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2391312,"sourceType":"datasetVersion","datasetId":1445766}],"dockerImageVersionId":30458,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense\nfrom keras.callbacks import ModelCheckpoint\n\n# Load the UCI HAR dataset\nX = pd.read_csv('/kaggle/input/ucihar-dataset/UCI-HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None)\ny = pd.read_csv('/kaggle/input/ucihar-dataset/UCI-HAR Dataset/train/y_train.txt', delim_whitespace=True, header=None)\n\n# Map the activity labels to human-readable names\nLABELS = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\nactivity_map = {1: 'Walking', 2: 'Walking Upstairs', 3: 'Walking Downstairs', 4: 'Sitting', 5: 'Standing', 6: 'Laying'}\ny = y[0].map(activity_map)\n\n# Convert human-readable labels to integer indices\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n# Normalize the sensor data\nscaler = StandardScaler()\nX = scaler.fit_transform(X.values)\n\n# Define window size and calculate stride dynamically\nwindow_size = 128\nstride = X.shape[0] // (X.shape[0] // window_size)\n\n# Generate sliding window samples\nX_sliding = []\ny_sliding = []\nfor i in range(0, len(X), stride):\n    if i + window_size > len(X):\n        break\n    X_sliding.append(X[i:i+window_size])\n    y_sliding.append(y[i+window_size-1])\n\nX_sliding = np.array(X_sliding)\ny_sliding = np.array(y_sliding)\n\n# Convert activity labels to one-hot encoded vectors\ny_sliding = to_categorical(y_sliding, num_classes=len(LABELS))\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_sliding, y_sliding, test_size=0.3, random_state=42)\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(window_size, X_train.shape[2])))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(LSTM(units=64, return_sequences=True))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(units=64))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=len(LABELS), activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up model checkpoint to save the best model\ncheckpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n\n# Train the model\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1, callbacks=[checkpoint])\n\n# Train the model\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1, callbacks=[checkpoint])\n\n# Print training loss and accuracy at each epoch\nfor epoch in range(1, len(history.history['loss']) + 1):\n    print(f'Epoch {epoch}/{len(history.history[\"loss\"])}')\n    print(f'Training Loss: {history.history[\"loss\"][epoch-1]:.4f} - Training Accuracy: {history.history[\"accuracy\"][epoch-1]:.4f}')\n    print(f'Validation Loss: {history.history[\"val_loss\"][epoch-1]:.4f} - Validation Accuracy: {history.history[\"val_accuracy\"][epoch-1]:.4f}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-20T12:36:08.850499Z","iopub.execute_input":"2023-04-20T12:36:08.851667Z","iopub.status.idle":"2023-04-20T12:37:02.295695Z","shell.execute_reply.started":"2023-04-20T12:36:08.851619Z","shell.execute_reply":"2023-04-20T12:37:02.294788Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/100\n2/2 [==============================] - ETA: 0s - loss: 1.8486 - accuracy: 0.2571\nEpoch 1: val_loss improved from inf to 1.65385, saving model to best_model.h5\n2/2 [==============================] - 6s 2s/step - loss: 1.8486 - accuracy: 0.2571 - val_loss: 1.6539 - val_accuracy: 0.2500\nEpoch 2/100\n2/2 [==============================] - ETA: 0s - loss: 1.4226 - accuracy: 0.4857\nEpoch 2: val_loss improved from 1.65385 to 1.52651, saving model to best_model.h5\n2/2 [==============================] - 0s 132ms/step - loss: 1.4226 - accuracy: 0.4857 - val_loss: 1.5265 - val_accuracy: 0.2500\nEpoch 3/100\n2/2 [==============================] - ETA: 0s - loss: 1.4143 - accuracy: 0.4571\nEpoch 3: val_loss improved from 1.52651 to 1.43372, saving model to best_model.h5\n2/2 [==============================] - 0s 130ms/step - loss: 1.4143 - accuracy: 0.4571 - val_loss: 1.4337 - val_accuracy: 0.5000\nEpoch 4/100\n2/2 [==============================] - ETA: 0s - loss: 1.3449 - accuracy: 0.5429\nEpoch 4: val_loss improved from 1.43372 to 1.42007, saving model to best_model.h5\n2/2 [==============================] - 0s 132ms/step - loss: 1.3449 - accuracy: 0.5429 - val_loss: 1.4201 - val_accuracy: 0.5000\nEpoch 5/100\n2/2 [==============================] - ETA: 0s - loss: 1.2079 - accuracy: 0.6571\nEpoch 5: val_loss improved from 1.42007 to 1.39884, saving model to best_model.h5\n2/2 [==============================] - 0s 145ms/step - loss: 1.2079 - accuracy: 0.6571 - val_loss: 1.3988 - val_accuracy: 0.5000\nEpoch 6/100\n2/2 [==============================] - ETA: 0s - loss: 1.1702 - accuracy: 0.6000\nEpoch 6: val_loss improved from 1.39884 to 1.36793, saving model to best_model.h5\n2/2 [==============================] - 0s 163ms/step - loss: 1.1702 - accuracy: 0.6000 - val_loss: 1.3679 - val_accuracy: 0.5000\nEpoch 7/100\n2/2 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.6857\nEpoch 7: val_loss improved from 1.36793 to 1.35263, saving model to best_model.h5\n2/2 [==============================] - 0s 143ms/step - loss: 1.1376 - accuracy: 0.6857 - val_loss: 1.3526 - val_accuracy: 0.5000\nEpoch 8/100\n2/2 [==============================] - ETA: 0s - loss: 1.0696 - accuracy: 0.6286\nEpoch 8: val_loss improved from 1.35263 to 1.29631, saving model to best_model.h5\n2/2 [==============================] - 0s 150ms/step - loss: 1.0696 - accuracy: 0.6286 - val_loss: 1.2963 - val_accuracy: 0.5000\nEpoch 9/100\n2/2 [==============================] - ETA: 0s - loss: 1.0890 - accuracy: 0.5714\nEpoch 9: val_loss improved from 1.29631 to 1.23390, saving model to best_model.h5\n2/2 [==============================] - 0s 137ms/step - loss: 1.0890 - accuracy: 0.5714 - val_loss: 1.2339 - val_accuracy: 0.5000\nEpoch 10/100\n2/2 [==============================] - ETA: 0s - loss: 0.9287 - accuracy: 0.7714\nEpoch 10: val_loss improved from 1.23390 to 1.21165, saving model to best_model.h5\n2/2 [==============================] - 0s 140ms/step - loss: 0.9287 - accuracy: 0.7714 - val_loss: 1.2116 - val_accuracy: 0.5000\nEpoch 11/100\n2/2 [==============================] - ETA: 0s - loss: 0.9189 - accuracy: 0.8286\nEpoch 11: val_loss improved from 1.21165 to 1.19283, saving model to best_model.h5\n2/2 [==============================] - 0s 132ms/step - loss: 0.9189 - accuracy: 0.8286 - val_loss: 1.1928 - val_accuracy: 0.5000\nEpoch 12/100\n2/2 [==============================] - ETA: 0s - loss: 0.8374 - accuracy: 0.7714\nEpoch 12: val_loss improved from 1.19283 to 1.11481, saving model to best_model.h5\n2/2 [==============================] - 0s 139ms/step - loss: 0.8374 - accuracy: 0.7714 - val_loss: 1.1148 - val_accuracy: 0.5000\nEpoch 13/100\n2/2 [==============================] - ETA: 0s - loss: 0.8661 - accuracy: 0.8000\nEpoch 13: val_loss did not improve from 1.11481\n2/2 [==============================] - 0s 104ms/step - loss: 0.8661 - accuracy: 0.8000 - val_loss: 1.1331 - val_accuracy: 0.5000\nEpoch 14/100\n2/2 [==============================] - ETA: 0s - loss: 0.7281 - accuracy: 0.8286\nEpoch 14: val_loss did not improve from 1.11481\n2/2 [==============================] - 0s 111ms/step - loss: 0.7281 - accuracy: 0.8286 - val_loss: 1.1777 - val_accuracy: 0.5000\nEpoch 15/100\n2/2 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.8000\nEpoch 15: val_loss did not improve from 1.11481\n2/2 [==============================] - 0s 111ms/step - loss: 0.7478 - accuracy: 0.8000 - val_loss: 1.1617 - val_accuracy: 0.5000\nEpoch 16/100\n2/2 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.8857\nEpoch 16: val_loss improved from 1.11481 to 1.08347, saving model to best_model.h5\n2/2 [==============================] - 0s 146ms/step - loss: 0.6891 - accuracy: 0.8857 - val_loss: 1.0835 - val_accuracy: 0.5000\nEpoch 17/100\n2/2 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.8857\nEpoch 17: val_loss improved from 1.08347 to 1.02511, saving model to best_model.h5\n2/2 [==============================] - 0s 140ms/step - loss: 0.6522 - accuracy: 0.8857 - val_loss: 1.0251 - val_accuracy: 0.5000\nEpoch 18/100\n2/2 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.8571\nEpoch 18: val_loss improved from 1.02511 to 0.97754, saving model to best_model.h5\n2/2 [==============================] - 0s 140ms/step - loss: 0.6509 - accuracy: 0.8571 - val_loss: 0.9775 - val_accuracy: 0.5000\nEpoch 19/100\n2/2 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.9143\nEpoch 19: val_loss improved from 0.97754 to 0.92889, saving model to best_model.h5\n2/2 [==============================] - 0s 138ms/step - loss: 0.4922 - accuracy: 0.9143 - val_loss: 0.9289 - val_accuracy: 0.5000\nEpoch 20/100\n2/2 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.8571\nEpoch 20: val_loss improved from 0.92889 to 0.91294, saving model to best_model.h5\n2/2 [==============================] - 0s 148ms/step - loss: 0.4788 - accuracy: 0.8571 - val_loss: 0.9129 - val_accuracy: 0.5000\nEpoch 21/100\n2/2 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.9714\nEpoch 21: val_loss improved from 0.91294 to 0.90144, saving model to best_model.h5\n2/2 [==============================] - 0s 140ms/step - loss: 0.4251 - accuracy: 0.9714 - val_loss: 0.9014 - val_accuracy: 0.7500\nEpoch 22/100\n2/2 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.9429\nEpoch 22: val_loss improved from 0.90144 to 0.87932, saving model to best_model.h5\n2/2 [==============================] - 0s 140ms/step - loss: 0.3794 - accuracy: 0.9429 - val_loss: 0.8793 - val_accuracy: 0.5000\nEpoch 23/100\n2/2 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.9143\nEpoch 23: val_loss did not improve from 0.87932\n2/2 [==============================] - 0s 122ms/step - loss: 0.3265 - accuracy: 0.9143 - val_loss: 0.8825 - val_accuracy: 0.5000\nEpoch 24/100\n2/2 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.9143\nEpoch 24: val_loss did not improve from 0.87932\n2/2 [==============================] - 0s 101ms/step - loss: 0.3966 - accuracy: 0.9143 - val_loss: 0.8951 - val_accuracy: 0.5000\nEpoch 25/100\n2/2 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.9714\nEpoch 25: val_loss did not improve from 0.87932\n2/2 [==============================] - 0s 107ms/step - loss: 0.3626 - accuracy: 0.9714 - val_loss: 0.9121 - val_accuracy: 0.5000\nEpoch 26/100\n2/2 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9714\nEpoch 26: val_loss did not improve from 0.87932\n2/2 [==============================] - 0s 102ms/step - loss: 0.2509 - accuracy: 0.9714 - val_loss: 0.9630 - val_accuracy: 0.7500\nEpoch 27/100\n2/2 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 1.0000\nEpoch 27: val_loss did not improve from 0.87932\n2/2 [==============================] - 0s 103ms/step - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.7500\nEpoch 28/100\n2/2 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9714\nEpoch 28: val_loss did not improve from 0.87932\n2/2 [==============================] - 0s 111ms/step - loss: 0.2573 - accuracy: 0.9714 - val_loss: 0.9487 - val_accuracy: 0.7500\nEpoch 29/100\n2/2 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 1.0000\nEpoch 29: val_loss improved from 0.87932 to 0.76338, saving model to best_model.h5\n2/2 [==============================] - 0s 143ms/step - loss: 0.1908 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.7500\nEpoch 30/100\n2/2 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 1.0000\nEpoch 30: val_loss improved from 0.76338 to 0.62564, saving model to best_model.h5\n2/2 [==============================] - 0s 144ms/step - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 0.7500\nEpoch 31/100\n2/2 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 1.0000\nEpoch 31: val_loss improved from 0.62564 to 0.59296, saving model to best_model.h5\n2/2 [==============================] - 0s 135ms/step - loss: 0.2239 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.7500\nEpoch 32/100\n2/2 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 1.0000\nEpoch 32: val_loss improved from 0.59296 to 0.57924, saving model to best_model.h5\n2/2 [==============================] - 0s 135ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.7500\nEpoch 33/100\n2/2 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9714\nEpoch 33: val_loss improved from 0.57924 to 0.57490, saving model to best_model.h5\n2/2 [==============================] - 0s 142ms/step - loss: 0.1843 - accuracy: 0.9714 - val_loss: 0.5749 - val_accuracy: 0.7500\nEpoch 34/100\n2/2 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 1.0000\nEpoch 34: val_loss did not improve from 0.57490\n2/2 [==============================] - 0s 115ms/step - loss: 0.1758 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.7500\nEpoch 35/100\n2/2 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 1.0000\nEpoch 35: val_loss did not improve from 0.57490\n2/2 [==============================] - 0s 111ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.7500\nEpoch 36/100\n2/2 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 1.0000\nEpoch 36: val_loss did not improve from 0.57490\n2/2 [==============================] - 0s 116ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 0.5810 - val_accuracy: 0.7500\nEpoch 37/100\n2/2 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 1.0000\nEpoch 37: val_loss improved from 0.57490 to 0.53947, saving model to best_model.h5\n2/2 [==============================] - 0s 148ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.7500\nEpoch 38/100\n2/2 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 1.0000\nEpoch 38: val_loss improved from 0.53947 to 0.46179, saving model to best_model.h5\n2/2 [==============================] - 0s 143ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.7500\nEpoch 39/100\n2/2 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 1.0000\nEpoch 39: val_loss improved from 0.46179 to 0.35275, saving model to best_model.h5\n2/2 [==============================] - 0s 142ms/step - loss: 0.0999 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.7500\nEpoch 40/100\n2/2 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\nEpoch 40: val_loss improved from 0.35275 to 0.26131, saving model to best_model.h5\n2/2 [==============================] - 0s 135ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 1.0000\nEpoch 41/100\n2/2 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 1.0000\nEpoch 41: val_loss improved from 0.26131 to 0.25015, saving model to best_model.h5\n2/2 [==============================] - 0s 133ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 1.0000\nEpoch 42/100\n2/2 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 1.0000\nEpoch 42: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 116ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 1.0000\nEpoch 43/100\n2/2 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 1.0000\nEpoch 43: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 109ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.7500\nEpoch 44/100\n2/2 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 1.0000\nEpoch 44: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 117ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.7500\nEpoch 45/100\n2/2 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 1.0000\nEpoch 45: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 115ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.7500\nEpoch 46/100\n2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\nEpoch 46: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 114ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.7500\nEpoch 47/100\n2/2 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 1.0000\nEpoch 47: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 111ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.7500\nEpoch 48/100\n2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\nEpoch 48: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 139ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.7500\nEpoch 49/100\n2/2 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 1.0000\nEpoch 49: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 129ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.7500\nEpoch 50/100\n2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 1.0000\nEpoch 50: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 140ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.7500\nEpoch 51/100\n2/2 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 1.0000\nEpoch 51: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 118ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.7500\nEpoch 52/100\n2/2 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 1.0000\nEpoch 52: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 129ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.7500\nEpoch 53/100\n2/2 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 1.0000\nEpoch 53: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 107ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.7500\nEpoch 54/100\n2/2 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.0000\nEpoch 54: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 101ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.7500\nEpoch 55/100\n2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000\nEpoch 55: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 108ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.7500\nEpoch 56/100\n2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 1.0000\nEpoch 56: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 112ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.7500\nEpoch 57/100\n2/2 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 1.0000\nEpoch 57: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 105ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.7500\nEpoch 58/100\n2/2 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 1.0000\nEpoch 58: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 105ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.7500\nEpoch 59/100\n2/2 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 1.0000\nEpoch 59: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 109ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7500\nEpoch 60/100\n2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.0000\nEpoch 60: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 108ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.7500\nEpoch 61/100\n2/2 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000\nEpoch 61: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 110ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 0.7500\nEpoch 62/100\n2/2 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 1.0000\nEpoch 62: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 101ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.7500\nEpoch 63/100\n2/2 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.0000\nEpoch 63: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 105ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.7500\nEpoch 64/100\n2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.0000\nEpoch 64: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 108ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.5674 - val_accuracy: 0.7500\nEpoch 65/100\n2/2 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.0000\nEpoch 65: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 102ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.7500\nEpoch 66/100\n2/2 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000\nEpoch 66: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 105ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.7500\nEpoch 67/100\n2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 1.0000\nEpoch 67: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 103ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 1.0000\nEpoch 68/100\n2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 1.0000\nEpoch 68: val_loss did not improve from 0.25015\n2/2 [==============================] - 0s 109ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 1.0000\nEpoch 69/100\n2/2 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.0000\nEpoch 69: val_loss improved from 0.25015 to 0.24451, saving model to best_model.h5\n2/2 [==============================] - 0s 133ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 1.0000\nEpoch 70/100\n2/2 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000\nEpoch 70: val_loss improved from 0.24451 to 0.22145, saving model to best_model.h5\n2/2 [==============================] - 0s 143ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 1.0000\nEpoch 71/100\n2/2 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.0000\nEpoch 71: val_loss improved from 0.22145 to 0.21790, saving model to best_model.h5\n2/2 [==============================] - 0s 140ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 1.0000\nEpoch 72/100\n2/2 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000\nEpoch 72: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 106ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 1.0000\nEpoch 73/100\n2/2 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.0000\nEpoch 73: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 105ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 1.0000\nEpoch 74/100\n2/2 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.0000\nEpoch 74: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 114ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.7500\nEpoch 75/100\n2/2 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\nEpoch 75: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 107ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.7500\nEpoch 76/100\n2/2 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000\nEpoch 76: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 107ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.7500\nEpoch 77/100\n2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 1.0000\nEpoch 77: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 102ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.7500\nEpoch 78/100\n2/2 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.0000\nEpoch 78: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 109ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.7500\nEpoch 79/100\n2/2 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.0000\nEpoch 79: val_loss did not improve from 0.21790\n2/2 [==============================] - 0s 118ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.7500\nEpoch 80/100\n2/2 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.0000\nEpoch 80: val_loss improved from 0.21790 to 0.14413, saving model to best_model.h5\n2/2 [==============================] - 0s 147ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 1.0000\nEpoch 81/100\n2/2 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000\nEpoch 81: val_loss improved from 0.14413 to 0.07564, saving model to best_model.h5\n2/2 [==============================] - 0s 136ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\nEpoch 82/100\n2/2 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000\nEpoch 82: val_loss improved from 0.07564 to 0.03121, saving model to best_model.h5\n2/2 [==============================] - 0s 141ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000\nEpoch 83/100\n2/2 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\nEpoch 83: val_loss improved from 0.03121 to 0.02493, saving model to best_model.h5\n2/2 [==============================] - 0s 138ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\nEpoch 84/100\n2/2 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000\nEpoch 84: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 115ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\nEpoch 85/100\n2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 1.0000\nEpoch 85: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 109ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.7500\nEpoch 86/100\n2/2 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.0000\nEpoch 86: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 104ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.5000\nEpoch 87/100\n2/2 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000\nEpoch 87: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.4595 - val_accuracy: 0.5000\nEpoch 88/100\n2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 1.0000\nEpoch 88: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.5000\nEpoch 89/100\n2/2 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 1.0000\nEpoch 89: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.4613 - val_accuracy: 0.5000\nEpoch 90/100\n2/2 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000\nEpoch 90: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 115ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.4450 - val_accuracy: 0.5000\nEpoch 91/100\n2/2 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000\nEpoch 91: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 121ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.3657 - val_accuracy: 0.5000\nEpoch 92/100\n2/2 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\nEpoch 92: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 110ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1678 - val_accuracy: 0.7500\nEpoch 93/100\n2/2 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.0000\nEpoch 93: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.7500\nEpoch 94/100\n2/2 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000\nEpoch 94: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.1188 - val_accuracy: 0.7500\nEpoch 95/100\n2/2 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000\nEpoch 95: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.0859 - val_accuracy: 0.7500\nEpoch 96/100\n2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.0000\nEpoch 96: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 113ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.0489 - val_accuracy: 0.7500\nEpoch 97/100\n2/2 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\nEpoch 97: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.7500\nEpoch 98/100\n2/2 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\nEpoch 98: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 112ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.7500\nEpoch 99/100\n2/2 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\nEpoch 99: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 109ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.7500\nEpoch 100/100\n2/2 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\nEpoch 100: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 125ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.7500\nEpoch 1/100\n2/2 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.0000\nEpoch 1: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 141ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.7500\nEpoch 2/100\n2/2 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\nEpoch 2: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.7500\nEpoch 3/100\n2/2 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\nEpoch 3: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.7500\nEpoch 4/100\n2/2 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000\nEpoch 4: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 99ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.7500\nEpoch 5/100\n2/2 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\nEpoch 5: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 99ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.7500\nEpoch 6/100\n2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\nEpoch 6: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.7500\nEpoch 7/100\n2/2 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000\nEpoch 7: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.7500\nEpoch 8/100\n2/2 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000\nEpoch 8: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 109ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.7500\nEpoch 9/100\n2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\nEpoch 9: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.7500\nEpoch 10/100\n2/2 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\nEpoch 10: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.0416 - val_accuracy: 0.7500\nEpoch 11/100\n2/2 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\nEpoch 11: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 109ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.7500\nEpoch 12/100\n2/2 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\nEpoch 12: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.0794 - val_accuracy: 0.7500\nEpoch 13/100\n2/2 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\nEpoch 13: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.0998 - val_accuracy: 0.7500\nEpoch 14/100\n2/2 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\nEpoch 14: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 110ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1120 - val_accuracy: 0.7500\nEpoch 15/100\n2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\nEpoch 15: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 111ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.7500\nEpoch 16/100\n2/2 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\nEpoch 16: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 114ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1187 - val_accuracy: 0.7500\nEpoch 17/100\n2/2 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\nEpoch 17: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.7500\nEpoch 18/100\n2/2 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\nEpoch 18: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 102ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.1188 - val_accuracy: 0.7500\nEpoch 19/100\n2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\nEpoch 19: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.7500\nEpoch 20/100\n2/2 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\nEpoch 20: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.7500\nEpoch 21/100\n2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\nEpoch 21: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 99ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.7500\nEpoch 22/100\n2/2 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\nEpoch 22: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1273 - val_accuracy: 0.7500\nEpoch 23/100\n2/2 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000\nEpoch 23: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.1562 - val_accuracy: 0.7500\nEpoch 24/100\n2/2 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\nEpoch 24: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 113ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.7500\nEpoch 25/100\n2/2 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\nEpoch 25: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 100ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.7500\nEpoch 26/100\n2/2 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.0000\nEpoch 26: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 114ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.7500\nEpoch 27/100\n2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\nEpoch 27: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 110ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.2970 - val_accuracy: 0.7500\nEpoch 28/100\n2/2 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\nEpoch 28: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.7500\nEpoch 29/100\n2/2 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\nEpoch 29: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3720 - val_accuracy: 0.7500\nEpoch 30/100\n2/2 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000\nEpoch 30: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 111ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.5000\nEpoch 31/100\n2/2 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\nEpoch 31: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 116ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.4089 - val_accuracy: 0.5000\nEpoch 32/100\n2/2 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000\nEpoch 32: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 102ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4257 - val_accuracy: 0.5000\nEpoch 33/100\n2/2 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\nEpoch 33: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.4834 - val_accuracy: 0.5000\nEpoch 34/100\n2/2 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000\nEpoch 34: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 100ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.5000\nEpoch 35/100\n2/2 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\nEpoch 35: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5353 - val_accuracy: 0.5000\nEpoch 36/100\n2/2 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\nEpoch 36: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.5480 - val_accuracy: 0.5000\nEpoch 37/100\n2/2 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\nEpoch 37: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 113ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.5567 - val_accuracy: 0.5000\nEpoch 38/100\n2/2 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\nEpoch 38: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.5000\nEpoch 39/100\n2/2 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\nEpoch 39: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 110ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5334 - val_accuracy: 0.5000\nEpoch 40/100\n2/2 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\nEpoch 40: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 104ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.5000\nEpoch 41/100\n2/2 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\nEpoch 41: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 112ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.5000\nEpoch 42/100\n2/2 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\nEpoch 42: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 111ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5399 - val_accuracy: 0.5000\nEpoch 43/100\n2/2 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\nEpoch 43: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5568 - val_accuracy: 0.5000\nEpoch 44/100\n2/2 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\nEpoch 44: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 115ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5393 - val_accuracy: 0.5000\nEpoch 45/100\n2/2 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\nEpoch 45: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.4455 - val_accuracy: 0.7500\nEpoch 46/100\n2/2 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\nEpoch 46: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3685 - val_accuracy: 0.7500\nEpoch 47/100\n2/2 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\nEpoch 47: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 102ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.7500\nEpoch 48/100\n2/2 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\nEpoch 48: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 113ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.7500\nEpoch 49/100\n2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\nEpoch 49: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.3009 - val_accuracy: 0.7500\nEpoch 50/100\n2/2 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\nEpoch 50: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 136ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2931 - val_accuracy: 0.7500\nEpoch 51/100\n2/2 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\nEpoch 51: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.7500\nEpoch 52/100\n2/2 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\nEpoch 52: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2860 - val_accuracy: 0.7500\nEpoch 53/100\n2/2 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\nEpoch 53: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.2956 - val_accuracy: 0.7500\nEpoch 54/100\n2/2 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\nEpoch 54: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 97ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3092 - val_accuracy: 0.7500\nEpoch 55/100\n2/2 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\nEpoch 55: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.7500\nEpoch 56/100\n2/2 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\nEpoch 56: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 116ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.7500\nEpoch 57/100\n2/2 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000\nEpoch 57: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 111ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3270 - val_accuracy: 0.7500\nEpoch 58/100\n2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\nEpoch 58: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3298 - val_accuracy: 0.7500\nEpoch 59/100\n2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000\nEpoch 59: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 102ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.3363 - val_accuracy: 0.7500\nEpoch 60/100\n2/2 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\nEpoch 60: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.7500\nEpoch 61/100\n2/2 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\nEpoch 61: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4658 - val_accuracy: 0.7500\nEpoch 62/100\n2/2 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\nEpoch 62: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 109ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.5000\nEpoch 63/100\n2/2 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\nEpoch 63: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 116ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.8490 - val_accuracy: 0.5000\nEpoch 64/100\n2/2 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\nEpoch 64: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 104ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.9485 - val_accuracy: 0.5000\nEpoch 65/100\n2/2 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\nEpoch 65: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 102ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.0194 - val_accuracy: 0.5000\nEpoch 66/100\n2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000\nEpoch 66: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 112ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.0624 - val_accuracy: 0.5000\nEpoch 67/100\n2/2 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\nEpoch 67: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.0751 - val_accuracy: 0.5000\nEpoch 68/100\n2/2 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\nEpoch 68: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.0394 - val_accuracy: 0.5000\nEpoch 69/100\n2/2 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\nEpoch 69: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.9762 - val_accuracy: 0.5000\nEpoch 70/100\n2/2 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\nEpoch 70: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 111ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.8875 - val_accuracy: 0.5000\nEpoch 71/100\n2/2 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\nEpoch 71: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.7500\nEpoch 72/100\n2/2 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\nEpoch 72: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 112ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.7675 - val_accuracy: 0.7500\nEpoch 73/100\n2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\nEpoch 73: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 109ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.7519 - val_accuracy: 0.7500\nEpoch 74/100\n2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\nEpoch 74: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.7443 - val_accuracy: 0.7500\nEpoch 75/100\n2/2 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\nEpoch 75: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 95ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7555 - val_accuracy: 0.7500\nEpoch 76/100\n2/2 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\nEpoch 76: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 99ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.7759 - val_accuracy: 0.7500\nEpoch 77/100\n2/2 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\nEpoch 77: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 102ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.8614 - val_accuracy: 0.5000\nEpoch 78/100\n2/2 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.0000\nEpoch 78: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 1.0000\nEpoch 79/100\n2/2 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8857\nEpoch 79: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.4517 - accuracy: 0.8857 - val_loss: 0.3689 - val_accuracy: 0.7500\nEpoch 80/100\n2/2 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9714\nEpoch 80: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 112ms/step - loss: 0.1142 - accuracy: 0.9714 - val_loss: 0.6366 - val_accuracy: 0.7500\nEpoch 81/100\n2/2 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9714\nEpoch 81: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 114ms/step - loss: 0.1325 - accuracy: 0.9714 - val_loss: 1.8053 - val_accuracy: 0.7500\nEpoch 82/100\n2/2 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9143\nEpoch 82: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 110ms/step - loss: 0.2007 - accuracy: 0.9143 - val_loss: 0.0362 - val_accuracy: 1.0000\nEpoch 83/100\n2/2 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.8857\nEpoch 83: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 110ms/step - loss: 0.4694 - accuracy: 0.8857 - val_loss: 0.8675 - val_accuracy: 0.7500\nEpoch 84/100\n2/2 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9143\nEpoch 84: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.1723 - accuracy: 0.9143 - val_loss: 1.3722 - val_accuracy: 0.7500\nEpoch 85/100\n2/2 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9143\nEpoch 85: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.1513 - accuracy: 0.9143 - val_loss: 1.1277 - val_accuracy: 0.7500\nEpoch 86/100\n2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 1.0000\nEpoch 86: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 103ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 1.0000\nEpoch 87/100\n2/2 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 1.0000\nEpoch 87: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 106ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 1.0000\nEpoch 88/100\n2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 1.0000\nEpoch 88: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 104ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 1.0000\nEpoch 89/100\n2/2 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9714\nEpoch 89: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 104ms/step - loss: 0.1086 - accuracy: 0.9714 - val_loss: 0.4818 - val_accuracy: 0.7500\nEpoch 90/100\n2/2 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.0000\nEpoch 90: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 121ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.7500\nEpoch 91/100\n2/2 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\nEpoch 91: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 134ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.7500\nEpoch 92/100\n2/2 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 1.0000\nEpoch 92: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 143ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.7500\nEpoch 93/100\n2/2 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9714\nEpoch 93: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 115ms/step - loss: 0.0848 - accuracy: 0.9714 - val_loss: 1.0557 - val_accuracy: 0.7500\nEpoch 94/100\n2/2 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000\nEpoch 94: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 131ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.7500\nEpoch 95/100\n2/2 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9714\nEpoch 95: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 107ms/step - loss: 0.1191 - accuracy: 0.9714 - val_loss: 1.2375 - val_accuracy: 0.7500\nEpoch 96/100\n2/2 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000\nEpoch 96: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 108ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.2436 - val_accuracy: 0.7500\nEpoch 97/100\n2/2 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 1.0000\nEpoch 97: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 100ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.7500\nEpoch 98/100\n2/2 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000\nEpoch 98: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 105ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 1.0000\nEpoch 99/100\n2/2 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 1.0000\nEpoch 99: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 141ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\nEpoch 100/100\n2/2 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9429\nEpoch 100: val_loss did not improve from 0.02493\n2/2 [==============================] - 0s 101ms/step - loss: 0.2025 - accuracy: 0.9429 - val_loss: 0.2032 - val_accuracy: 0.7500\nEpoch 1/100\nTraining Loss: 0.0168 - Training Accuracy: 1.0000\nValidation Loss: 0.9819 - Validation Accuracy: 0.7500\nEpoch 2/100\nTraining Loss: 0.0154 - Training Accuracy: 1.0000\nValidation Loss: 0.9748 - Validation Accuracy: 0.7500\nEpoch 3/100\nTraining Loss: 0.0141 - Training Accuracy: 1.0000\nValidation Loss: 0.9808 - Validation Accuracy: 0.7500\nEpoch 4/100\nTraining Loss: 0.0158 - Training Accuracy: 1.0000\nValidation Loss: 0.9907 - Validation Accuracy: 0.7500\nEpoch 5/100\nTraining Loss: 0.0176 - Training Accuracy: 1.0000\nValidation Loss: 1.0006 - Validation Accuracy: 0.7500\nEpoch 6/100\nTraining Loss: 0.0101 - Training Accuracy: 1.0000\nValidation Loss: 0.9987 - Validation Accuracy: 0.7500\nEpoch 7/100\nTraining Loss: 0.0091 - Training Accuracy: 1.0000\nValidation Loss: 0.9891 - Validation Accuracy: 0.7500\nEpoch 8/100\nTraining Loss: 0.0227 - Training Accuracy: 1.0000\nValidation Loss: 0.9940 - Validation Accuracy: 0.7500\nEpoch 9/100\nTraining Loss: 0.0101 - Training Accuracy: 1.0000\nValidation Loss: 1.0133 - Validation Accuracy: 0.7500\nEpoch 10/100\nTraining Loss: 0.0155 - Training Accuracy: 1.0000\nValidation Loss: 1.0416 - Validation Accuracy: 0.7500\nEpoch 11/100\nTraining Loss: 0.0089 - Training Accuracy: 1.0000\nValidation Loss: 1.0618 - Validation Accuracy: 0.7500\nEpoch 12/100\nTraining Loss: 0.0140 - Training Accuracy: 1.0000\nValidation Loss: 1.0794 - Validation Accuracy: 0.7500\nEpoch 13/100\nTraining Loss: 0.0141 - Training Accuracy: 1.0000\nValidation Loss: 1.0998 - Validation Accuracy: 0.7500\nEpoch 14/100\nTraining Loss: 0.0136 - Training Accuracy: 1.0000\nValidation Loss: 1.1120 - Validation Accuracy: 0.7500\nEpoch 15/100\nTraining Loss: 0.0101 - Training Accuracy: 1.0000\nValidation Loss: 1.1152 - Validation Accuracy: 0.7500\nEpoch 16/100\nTraining Loss: 0.0111 - Training Accuracy: 1.0000\nValidation Loss: 1.1187 - Validation Accuracy: 0.7500\nEpoch 17/100\nTraining Loss: 0.0096 - Training Accuracy: 1.0000\nValidation Loss: 1.1158 - Validation Accuracy: 0.7500\nEpoch 18/100\nTraining Loss: 0.0135 - Training Accuracy: 1.0000\nValidation Loss: 1.1188 - Validation Accuracy: 0.7500\nEpoch 19/100\nTraining Loss: 0.0088 - Training Accuracy: 1.0000\nValidation Loss: 1.1234 - Validation Accuracy: 0.7500\nEpoch 20/100\nTraining Loss: 0.0098 - Training Accuracy: 1.0000\nValidation Loss: 1.1303 - Validation Accuracy: 0.7500\nEpoch 21/100\nTraining Loss: 0.0084 - Training Accuracy: 1.0000\nValidation Loss: 1.1300 - Validation Accuracy: 0.7500\nEpoch 22/100\nTraining Loss: 0.0095 - Training Accuracy: 1.0000\nValidation Loss: 1.1273 - Validation Accuracy: 0.7500\nEpoch 23/100\nTraining Loss: 0.0108 - Training Accuracy: 1.0000\nValidation Loss: 1.1562 - Validation Accuracy: 0.7500\nEpoch 24/100\nTraining Loss: 0.0151 - Training Accuracy: 1.0000\nValidation Loss: 1.1907 - Validation Accuracy: 0.7500\nEpoch 25/100\nTraining Loss: 0.0129 - Training Accuracy: 1.0000\nValidation Loss: 1.2238 - Validation Accuracy: 0.7500\nEpoch 26/100\nTraining Loss: 0.0103 - Training Accuracy: 1.0000\nValidation Loss: 1.2569 - Validation Accuracy: 0.7500\nEpoch 27/100\nTraining Loss: 0.0099 - Training Accuracy: 1.0000\nValidation Loss: 1.2970 - Validation Accuracy: 0.7500\nEpoch 28/100\nTraining Loss: 0.0164 - Training Accuracy: 1.0000\nValidation Loss: 1.3397 - Validation Accuracy: 0.7500\nEpoch 29/100\nTraining Loss: 0.0115 - Training Accuracy: 1.0000\nValidation Loss: 1.3720 - Validation Accuracy: 0.7500\nEpoch 30/100\nTraining Loss: 0.0128 - Training Accuracy: 1.0000\nValidation Loss: 1.3970 - Validation Accuracy: 0.5000\nEpoch 31/100\nTraining Loss: 0.0078 - Training Accuracy: 1.0000\nValidation Loss: 1.4089 - Validation Accuracy: 0.5000\nEpoch 32/100\nTraining Loss: 0.0087 - Training Accuracy: 1.0000\nValidation Loss: 1.4257 - Validation Accuracy: 0.5000\nEpoch 33/100\nTraining Loss: 0.0077 - Training Accuracy: 1.0000\nValidation Loss: 1.4834 - Validation Accuracy: 0.5000\nEpoch 34/100\nTraining Loss: 0.0091 - Training Accuracy: 1.0000\nValidation Loss: 1.5246 - Validation Accuracy: 0.5000\nEpoch 35/100\nTraining Loss: 0.0074 - Training Accuracy: 1.0000\nValidation Loss: 1.5353 - Validation Accuracy: 0.5000\nEpoch 36/100\nTraining Loss: 0.0131 - Training Accuracy: 1.0000\nValidation Loss: 1.5480 - Validation Accuracy: 0.5000\nEpoch 37/100\nTraining Loss: 0.0181 - Training Accuracy: 1.0000\nValidation Loss: 1.5567 - Validation Accuracy: 0.5000\nEpoch 38/100\nTraining Loss: 0.0136 - Training Accuracy: 1.0000\nValidation Loss: 1.5447 - Validation Accuracy: 0.5000\nEpoch 39/100\nTraining Loss: 0.0071 - Training Accuracy: 1.0000\nValidation Loss: 1.5334 - Validation Accuracy: 0.5000\nEpoch 40/100\nTraining Loss: 0.0062 - Training Accuracy: 1.0000\nValidation Loss: 1.5248 - Validation Accuracy: 0.5000\nEpoch 41/100\nTraining Loss: 0.0102 - Training Accuracy: 1.0000\nValidation Loss: 1.5248 - Validation Accuracy: 0.5000\nEpoch 42/100\nTraining Loss: 0.0076 - Training Accuracy: 1.0000\nValidation Loss: 1.5399 - Validation Accuracy: 0.5000\nEpoch 43/100\nTraining Loss: 0.0071 - Training Accuracy: 1.0000\nValidation Loss: 1.5568 - Validation Accuracy: 0.5000\nEpoch 44/100\nTraining Loss: 0.0076 - Training Accuracy: 1.0000\nValidation Loss: 1.5393 - Validation Accuracy: 0.5000\nEpoch 45/100\nTraining Loss: 0.0170 - Training Accuracy: 1.0000\nValidation Loss: 1.4455 - Validation Accuracy: 0.7500\nEpoch 46/100\nTraining Loss: 0.0056 - Training Accuracy: 1.0000\nValidation Loss: 1.3685 - Validation Accuracy: 0.7500\nEpoch 47/100\nTraining Loss: 0.0120 - Training Accuracy: 1.0000\nValidation Loss: 1.3302 - Validation Accuracy: 0.7500\nEpoch 48/100\nTraining Loss: 0.0049 - Training Accuracy: 1.0000\nValidation Loss: 1.3121 - Validation Accuracy: 0.7500\nEpoch 49/100\nTraining Loss: 0.0100 - Training Accuracy: 1.0000\nValidation Loss: 1.3009 - Validation Accuracy: 0.7500\nEpoch 50/100\nTraining Loss: 0.0045 - Training Accuracy: 1.0000\nValidation Loss: 1.2931 - Validation Accuracy: 0.7500\nEpoch 51/100\nTraining Loss: 0.0062 - Training Accuracy: 1.0000\nValidation Loss: 1.2877 - Validation Accuracy: 0.7500\nEpoch 52/100\nTraining Loss: 0.0075 - Training Accuracy: 1.0000\nValidation Loss: 1.2860 - Validation Accuracy: 0.7500\nEpoch 53/100\nTraining Loss: 0.0114 - Training Accuracy: 1.0000\nValidation Loss: 1.2956 - Validation Accuracy: 0.7500\nEpoch 54/100\nTraining Loss: 0.0060 - Training Accuracy: 1.0000\nValidation Loss: 1.3092 - Validation Accuracy: 0.7500\nEpoch 55/100\nTraining Loss: 0.0059 - Training Accuracy: 1.0000\nValidation Loss: 1.3231 - Validation Accuracy: 0.7500\nEpoch 56/100\nTraining Loss: 0.0078 - Training Accuracy: 1.0000\nValidation Loss: 1.3304 - Validation Accuracy: 0.7500\nEpoch 57/100\nTraining Loss: 0.0148 - Training Accuracy: 1.0000\nValidation Loss: 1.3270 - Validation Accuracy: 0.7500\nEpoch 58/100\nTraining Loss: 0.0084 - Training Accuracy: 1.0000\nValidation Loss: 1.3298 - Validation Accuracy: 0.7500\nEpoch 59/100\nTraining Loss: 0.0086 - Training Accuracy: 1.0000\nValidation Loss: 1.3363 - Validation Accuracy: 0.7500\nEpoch 60/100\nTraining Loss: 0.0069 - Training Accuracy: 1.0000\nValidation Loss: 1.3473 - Validation Accuracy: 0.7500\nEpoch 61/100\nTraining Loss: 0.0050 - Training Accuracy: 1.0000\nValidation Loss: 1.4658 - Validation Accuracy: 0.7500\nEpoch 62/100\nTraining Loss: 0.0047 - Training Accuracy: 1.0000\nValidation Loss: 1.6972 - Validation Accuracy: 0.5000\nEpoch 63/100\nTraining Loss: 0.0083 - Training Accuracy: 1.0000\nValidation Loss: 1.8490 - Validation Accuracy: 0.5000\nEpoch 64/100\nTraining Loss: 0.0079 - Training Accuracy: 1.0000\nValidation Loss: 1.9485 - Validation Accuracy: 0.5000\nEpoch 65/100\nTraining Loss: 0.0045 - Training Accuracy: 1.0000\nValidation Loss: 2.0194 - Validation Accuracy: 0.5000\nEpoch 66/100\nTraining Loss: 0.0086 - Training Accuracy: 1.0000\nValidation Loss: 2.0624 - Validation Accuracy: 0.5000\nEpoch 67/100\nTraining Loss: 0.0089 - Training Accuracy: 1.0000\nValidation Loss: 2.0751 - Validation Accuracy: 0.5000\nEpoch 68/100\nTraining Loss: 0.0054 - Training Accuracy: 1.0000\nValidation Loss: 2.0394 - Validation Accuracy: 0.5000\nEpoch 69/100\nTraining Loss: 0.0044 - Training Accuracy: 1.0000\nValidation Loss: 1.9762 - Validation Accuracy: 0.5000\nEpoch 70/100\nTraining Loss: 0.0053 - Training Accuracy: 1.0000\nValidation Loss: 1.8875 - Validation Accuracy: 0.5000\nEpoch 71/100\nTraining Loss: 0.0054 - Training Accuracy: 1.0000\nValidation Loss: 1.8065 - Validation Accuracy: 0.7500\nEpoch 72/100\nTraining Loss: 0.0118 - Training Accuracy: 1.0000\nValidation Loss: 1.7675 - Validation Accuracy: 0.7500\nEpoch 73/100\nTraining Loss: 0.0068 - Training Accuracy: 1.0000\nValidation Loss: 1.7519 - Validation Accuracy: 0.7500\nEpoch 74/100\nTraining Loss: 0.0068 - Training Accuracy: 1.0000\nValidation Loss: 1.7443 - Validation Accuracy: 0.7500\nEpoch 75/100\nTraining Loss: 0.0047 - Training Accuracy: 1.0000\nValidation Loss: 1.7555 - Validation Accuracy: 0.7500\nEpoch 76/100\nTraining Loss: 0.0098 - Training Accuracy: 1.0000\nValidation Loss: 1.7759 - Validation Accuracy: 0.7500\nEpoch 77/100\nTraining Loss: 0.0069 - Training Accuracy: 1.0000\nValidation Loss: 1.8614 - Validation Accuracy: 0.5000\nEpoch 78/100\nTraining Loss: 0.0206 - Training Accuracy: 1.0000\nValidation Loss: 0.1505 - Validation Accuracy: 1.0000\nEpoch 79/100\nTraining Loss: 0.4517 - Training Accuracy: 0.8857\nValidation Loss: 0.3689 - Validation Accuracy: 0.7500\nEpoch 80/100\nTraining Loss: 0.1142 - Training Accuracy: 0.9714\nValidation Loss: 0.6366 - Validation Accuracy: 0.7500\nEpoch 81/100\nTraining Loss: 0.1325 - Training Accuracy: 0.9714\nValidation Loss: 1.8053 - Validation Accuracy: 0.7500\nEpoch 82/100\nTraining Loss: 0.2007 - Training Accuracy: 0.9143\nValidation Loss: 0.0362 - Validation Accuracy: 1.0000\nEpoch 83/100\nTraining Loss: 0.4694 - Training Accuracy: 0.8857\nValidation Loss: 0.8675 - Validation Accuracy: 0.7500\nEpoch 84/100\nTraining Loss: 0.1723 - Training Accuracy: 0.9143\nValidation Loss: 1.3722 - Validation Accuracy: 0.7500\nEpoch 85/100\nTraining Loss: 0.1513 - Training Accuracy: 0.9143\nValidation Loss: 1.1277 - Validation Accuracy: 0.7500\nEpoch 86/100\nTraining Loss: 0.0674 - Training Accuracy: 1.0000\nValidation Loss: 0.2874 - Validation Accuracy: 1.0000\nEpoch 87/100\nTraining Loss: 0.0743 - Training Accuracy: 1.0000\nValidation Loss: 0.2755 - Validation Accuracy: 1.0000\nEpoch 88/100\nTraining Loss: 0.0426 - Training Accuracy: 1.0000\nValidation Loss: 0.2215 - Validation Accuracy: 1.0000\nEpoch 89/100\nTraining Loss: 0.1086 - Training Accuracy: 0.9714\nValidation Loss: 0.4818 - Validation Accuracy: 0.7500\nEpoch 90/100\nTraining Loss: 0.0430 - Training Accuracy: 1.0000\nValidation Loss: 0.7688 - Validation Accuracy: 0.7500\nEpoch 91/100\nTraining Loss: 0.0589 - Training Accuracy: 1.0000\nValidation Loss: 0.8569 - Validation Accuracy: 0.7500\nEpoch 92/100\nTraining Loss: 0.0467 - Training Accuracy: 1.0000\nValidation Loss: 0.9321 - Validation Accuracy: 0.7500\nEpoch 93/100\nTraining Loss: 0.0848 - Training Accuracy: 0.9714\nValidation Loss: 1.0557 - Validation Accuracy: 0.7500\nEpoch 94/100\nTraining Loss: 0.0235 - Training Accuracy: 1.0000\nValidation Loss: 1.1469 - Validation Accuracy: 0.7500\nEpoch 95/100\nTraining Loss: 0.1191 - Training Accuracy: 0.9714\nValidation Loss: 1.2375 - Validation Accuracy: 0.7500\nEpoch 96/100\nTraining Loss: 0.0260 - Training Accuracy: 1.0000\nValidation Loss: 1.2436 - Validation Accuracy: 0.7500\nEpoch 97/100\nTraining Loss: 0.0554 - Training Accuracy: 1.0000\nValidation Loss: 0.6882 - Validation Accuracy: 0.7500\nEpoch 98/100\nTraining Loss: 0.0158 - Training Accuracy: 1.0000\nValidation Loss: 0.0491 - Validation Accuracy: 1.0000\nEpoch 99/100\nTraining Loss: 0.0357 - Training Accuracy: 1.0000\nValidation Loss: 0.0383 - Validation Accuracy: 1.0000\nEpoch 100/100\nTraining Loss: 0.2025 - Training Accuracy: 0.9429\nValidation Loss: 0.2032 - Validation Accuracy: 0.7500\n","output_type":"stream"}],"execution_count":7}]}